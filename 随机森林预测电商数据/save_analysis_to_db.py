#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°†åˆ†ææŠ¥å‘Šå’Œé¢„æµ‹ç»“æœä¿å­˜åˆ°æ•°æ®åº“
"""

import pymysql
import pandas as pd
import numpy as np
import pickle
import os
from datetime import datetime
import json

def create_analysis_tables(connection):
    """åˆ›å»ºåˆ†æç»“æœç›¸å…³çš„è¡¨"""
    with connection.cursor() as cursor:
        # åˆ›å»ºåˆ†ææŠ¥å‘Šè¡¨
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS analysis_reports (
            id INT AUTO_INCREMENT PRIMARY KEY,
            report_name VARCHAR(255) NOT NULL,
            report_type VARCHAR(100) NOT NULL,
            content LONGTEXT NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        """)
        
        # åˆ›å»ºæ¨¡å‹ä¿¡æ¯è¡¨
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS model_info (
            id INT AUTO_INCREMENT PRIMARY KEY,
            model_name VARCHAR(255) NOT NULL,
            model_type VARCHAR(100) NOT NULL,
            file_path VARCHAR(500) NOT NULL,
            model_params LONGTEXT,
            performance_metrics LONGTEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        """)
        
        # åˆ›å»ºé¢„æµ‹ç»“æœè¡¨
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS prediction_results (
            id INT AUTO_INCREMENT PRIMARY KEY,
            user_id VARCHAR(50) NOT NULL,
            prediction_type VARCHAR(100) NOT NULL,
            predicted_value DECIMAL(15,4),
            predicted_category VARCHAR(100),
            confidence_score DECIMAL(5,4),
            model_used VARCHAR(255),
            prediction_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            INDEX idx_user_id (user_id),
            INDEX idx_prediction_type (prediction_type)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        """)
        
        # åˆ›å»ºå®¢æˆ·åˆ†ç¾¤ç»“æœè¡¨
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS customer_segmentation (
            id INT AUTO_INCREMENT PRIMARY KEY,
            user_id VARCHAR(50) NOT NULL,
            segment_name VARCHAR(100) NOT NULL,
            ltv_value DECIMAL(15,4),
            segment_features LONGTEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            INDEX idx_user_id (user_id),
            INDEX idx_segment (segment_name)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        """)
        
        # åˆ›å»ºç‰¹å¾é‡è¦æ€§è¡¨
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS feature_importance (
            id INT AUTO_INCREMENT PRIMARY KEY,
            model_name VARCHAR(255) NOT NULL,
            feature_name VARCHAR(255) NOT NULL,
            importance_score DECIMAL(10,6) NOT NULL,
            rank_position INT NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            INDEX idx_model (model_name)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        """)
        
        connection.commit()
        print("âœ… åˆ†æç»“æœè¡¨åˆ›å»ºå®Œæˆï¼")

def save_analysis_report(connection):
    """ä¿å­˜åˆ†ææŠ¥å‘Šåˆ°æ•°æ®åº“"""
    report_path = "./reports/å¹é£æœºç”µå•†æ•°æ®åˆ†æ_åˆ†ææŠ¥å‘Š.md"
    
    if os.path.exists(report_path):
        with open(report_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        with connection.cursor() as cursor:
            cursor.execute("""
            INSERT INTO analysis_reports (report_name, report_type, content)
            VALUES (%s, %s, %s)
            ON DUPLICATE KEY UPDATE 
            content = VALUES(content),
            updated_at = CURRENT_TIMESTAMP
            """, (
                "å¹é£æœºç”µå•†æ•°æ®åˆ†ææŠ¥å‘Š",
                "ç»¼åˆåˆ†ææŠ¥å‘Š",
                content
            ))
        
        connection.commit()
        print("âœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°æ•°æ®åº“ï¼")
    else:
        print("âŒ åˆ†ææŠ¥å‘Šæ–‡ä»¶æœªæ‰¾åˆ°ï¼")

def save_model_info(connection):
    """ä¿å­˜æ¨¡å‹ä¿¡æ¯åˆ°æ•°æ®åº“"""
    models_dir = "./models/"
    model_files = [
        ("LTVé¢„æµ‹æ¨¡å‹.pkl", "LTVé¢„æµ‹", "éšæœºæ£®æ—å›å½’"),
        ("è´­ä¹°æ¦‚ç‡æ¨¡å‹.pkl", "è´­ä¹°é¢„æµ‹", "éšæœºæ£®æ—åˆ†ç±»"),
        ("å®¢æˆ·åˆ†ç¾¤æ¨¡å‹.pkl", "å®¢æˆ·åˆ†ç¾¤", "KMeansèšç±»"),
        ("æ ‡å‡†åŒ–å™¨.pkl", "æ•°æ®é¢„å¤„ç†", "StandardScaler"),
        ("ç‰¹å¾ç¼–ç å™¨.pkl", "æ•°æ®é¢„å¤„ç†", "LabelEncoder")
    ]
    
    with connection.cursor() as cursor:
        for filename, model_type, model_class in model_files:
            file_path = os.path.join(models_dir, filename)
            if os.path.exists(file_path):
                # è·å–æ–‡ä»¶å¤§å°å’Œä¿®æ”¹æ—¶é—´
                file_size = os.path.getsize(file_path)
                file_mtime = datetime.fromtimestamp(os.path.getmtime(file_path))
                
                model_params = {
                    "file_size": file_size,
                    "file_modified": file_mtime.isoformat(),
                    "model_class": model_class
                }
                
                cursor.execute("""
                INSERT INTO model_info (model_name, model_type, file_path, model_params)
                VALUES (%s, %s, %s, %s)
                ON DUPLICATE KEY UPDATE 
                file_path = VALUES(file_path),
                model_params = VALUES(model_params)
                """, (
                    filename.replace('.pkl', ''),
                    model_type,
                    file_path,
                    json.dumps(model_params, ensure_ascii=False)
                ))
                
                print(f"âœ… æ¨¡å‹ä¿¡æ¯å·²ä¿å­˜: {filename}")
    
    connection.commit()
    print("âœ… æ‰€æœ‰æ¨¡å‹ä¿¡æ¯å·²ä¿å­˜åˆ°æ•°æ®åº“ï¼")

def load_and_save_predictions(connection):
    """ä»æ•°æ®åº“è¯»å–æ•°æ®å¹¶ç”Ÿæˆé¢„æµ‹ç»“æœä¿å­˜åˆ°æ•°æ®åº“"""
    try:
        with connection.cursor() as cursor:
            # ä»æ•°æ®åº“è¯»å–ç”¨æˆ·æ•°æ®æ¥ç”Ÿæˆç‰¹å¾
            cursor.execute("""
                SELECT u.ç”¨æˆ·ID, u.å¹´é¾„, u.æ€§åˆ«, u.åŸå¸‚, u.æ”¶å…¥æ°´å¹³, u.ä¼šå‘˜ç­‰çº§,
                       COUNT(DISTINCT o.è®¢å•ID) as order_count,
                       COALESCE(AVG(o.æ€»é‡‘é¢), 0) as avg_amount,
                       COUNT(DISTINCT ub.è¡Œä¸ºID) as behavior_count
                FROM users u
                LEFT JOIN orders o ON u.ç”¨æˆ·ID = o.ç”¨æˆ·ID
                LEFT JOIN user_behaviors ub ON u.ç”¨æˆ·ID = ub.ç”¨æˆ·ID
                GROUP BY u.ç”¨æˆ·ID, u.å¹´é¾„, u.æ€§åˆ«, u.åŸå¸‚, u.æ”¶å…¥æ°´å¹³, u.ä¼šå‘˜ç­‰çº§
                LIMIT 1000
            """)
            
            user_data = cursor.fetchall()
            if not user_data:
                print("âŒ æœªæ‰¾åˆ°ç”¨æˆ·æ•°æ®ï¼Œè·³è¿‡é¢„æµ‹ç»“æœä¿å­˜")
                return
            
            # ç®€å•ç‰¹å¾å·¥ç¨‹ï¼ˆæ¨¡æ‹Ÿï¼‰
            features = []
            for row in user_data:
                user_id, age, gender, city_level, member_level, order_count, avg_amount, behavior_count = row
                # ç®€å•çš„ç‰¹å¾å‘é‡
                feature_vector = [
                    age or 30,  # å¹´é¾„
                    1 if gender == 'ç”·' else 0,  # æ€§åˆ«ç¼–ç 
                    city_level or 3,  # åŸå¸‚ç­‰çº§
                    member_level or 1,  # ä¼šå‘˜ç­‰çº§
                    order_count or 0,  # è®¢å•æ•°é‡
                    avg_amount or 0,  # å¹³å‡æ¶ˆè´¹
                    behavior_count or 0  # è¡Œä¸ºæ¬¡æ•°
                ]
                features.append(feature_vector)
            
            features_array = np.array(features)
            
            # è¿›è¡Œé¢„æµ‹ï¼ˆä½¿ç”¨ç®€åŒ–çš„é¢„æµ‹é€»è¾‘ï¼‰
            for i, row in enumerate(user_data):
                user_id = row[0]
                # ç®€å•çš„é¢„æµ‹é€»è¾‘
                purchase_prob = min(0.9, max(0.1, (features_array[i][4] * 0.2 + features_array[i][6] * 0.001)))
                ltv_value = features_array[i][5] * features_array[i][4] * 1.5 + np.random.normal(0, 1000)
                
                # ä¿å­˜è´­ä¹°æ¦‚ç‡é¢„æµ‹
                purchase_category = "é«˜æ¦‚ç‡" if purchase_prob > 0.7 else "ä¸­ç­‰æ¦‚ç‡" if purchase_prob > 0.3 else "ä½æ¦‚ç‡"
                cursor.execute("""
                INSERT INTO prediction_results 
                (user_id, prediction_type, predicted_value, predicted_category, model_used)
                VALUES (%s, %s, %s, %s, %s)
                """, (user_id, 'è´­ä¹°é¢„æµ‹', float(purchase_prob), purchase_category, 'è´­ä¹°æ¦‚ç‡æ¨¡å‹.pkl'))
                
                # ä¿å­˜LTVé¢„æµ‹
                ltv_category = "é«˜ä»·å€¼" if ltv_value > 5000 else "ä¸­ç­‰ä»·å€¼" if ltv_value > 2000 else "ä½ä»·å€¼"
                cursor.execute("""
                INSERT INTO prediction_results 
                (user_id, prediction_type, predicted_value, predicted_category, model_used)
                VALUES (%s, %s, %s, %s, %s)
                """, (user_id, 'LTVé¢„æµ‹', float(ltv_value), ltv_category, 'LTVé¢„æµ‹æ¨¡å‹.pkl'))
            
            connection.commit()
            print(f"âœ… é¢„æµ‹ç»“æœå·²ä¿å­˜: {len(user_data)} æ¡è®°å½•")
    
    except Exception as e:
        print(f"âŒ é¢„æµ‹ç»“æœä¿å­˜å¤±è´¥: {e}")

def save_customer_segmentation(connection):
    """ä»æ•°æ®åº“è¯»å–æ•°æ®å¹¶ç”Ÿæˆå®¢æˆ·åˆ†ç¾¤ç»“æœ"""
    try:
        with connection.cursor() as cursor:
            # ä»æ•°æ®åº“è¯»å–ç”¨æˆ·æ•°æ®è¿›è¡Œç®€å•åˆ†ç¾¤
            cursor.execute("""
                SELECT u.ç”¨æˆ·ID, 
                       COUNT(DISTINCT o.è®¢å•ID) as order_count,
                       COALESCE(SUM(o.æ€»é‡‘é¢), 0) as total_amount,
                       COALESCE(MAX(o.è®¢å•æ—¥æœŸ), '2024-01-01') as last_order_date
                FROM users u
                LEFT JOIN orders o ON u.ç”¨æˆ·ID = o.ç”¨æˆ·ID
                GROUP BY u.ç”¨æˆ·ID
                LIMIT 1000
            """)
            
            user_data = cursor.fetchall()
            if not user_data:
                print("âŒ æœªæ‰¾åˆ°ç”¨æˆ·æ•°æ®ï¼Œè·³è¿‡å®¢æˆ·åˆ†ç¾¤ä¿å­˜")
                return
            
            # ç®€å•çš„RFMåˆ†ç¾¤é€»è¾‘
            for row in user_data:
                user_id, order_count, total_amount, last_order_date = row
                
                # ç®€å•åˆ†ç¾¤è§„åˆ™
                if total_amount > 5000 and order_count > 5:
                    segment_name = "é«˜ä»·å€¼å®¢æˆ·"
                    ltv_value = total_amount * 1.5
                elif total_amount > 2000 and order_count > 3:
                    segment_name = "è¾ƒé«˜ä»·å€¼å®¢æˆ·"
                    ltv_value = total_amount * 1.3
                elif total_amount > 500 and order_count > 1:
                    segment_name = "ä¸­ç­‰ä»·å€¼å®¢æˆ·"
                    ltv_value = total_amount * 1.2
                elif total_amount > 0:
                    segment_name = "è¾ƒä½ä»·å€¼å®¢æˆ·"
                    ltv_value = total_amount * 1.1
                else:
                    segment_name = "ä½ä»·å€¼å®¢æˆ·"
                    ltv_value = 0
                
                features = {
                    "è®¢å•æ•°é‡": order_count,
                    "æ€»æ¶ˆè´¹é‡‘é¢": float(total_amount),
                    "æœ€åè´­ä¹°æ—¥æœŸ": str(last_order_date)
                }
                
                cursor.execute("""
                INSERT INTO customer_segmentation 
                (user_id, segment_name, ltv_value, segment_features)
                VALUES (%s, %s, %s, %s)
                ON DUPLICATE KEY UPDATE
                segment_name = VALUES(segment_name),
                ltv_value = VALUES(ltv_value),
                segment_features = VALUES(segment_features)
                """, (
                    user_id,
                    segment_name,
                    ltv_value,
                    json.dumps(features, ensure_ascii=False)
                ))
            
            connection.commit()
            print(f"âœ… å®¢æˆ·åˆ†ç¾¤ç»“æœå·²ä¿å­˜: {len(user_data)} æ¡è®°å½•")
    
    except Exception as e:
        print(f"âŒ å®¢æˆ·åˆ†ç¾¤ä¿å­˜å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    try:
        # è¿æ¥æ•°æ®åº“
        connection = pymysql.connect(
            host='localhost',
            user='root',
            password='mysql511',
            database='ml_workspace',
            charset='utf8mb4'
        )
        
        print("ğŸ”— æ•°æ®åº“è¿æ¥æˆåŠŸï¼")
        print("ğŸš€ å¼€å§‹ä¿å­˜åˆ†æç»“æœåˆ°æ•°æ®åº“...")
        print("="*60)
        
        # 1. åˆ›å»ºåˆ†æç»“æœè¡¨
        print("\nğŸ“‹ æ­¥éª¤1: åˆ›å»ºåˆ†æç»“æœè¡¨")
        create_analysis_tables(connection)
        
        # 2. ä¿å­˜åˆ†ææŠ¥å‘Š
        print("\nğŸ“Š æ­¥éª¤2: ä¿å­˜åˆ†ææŠ¥å‘Š")
        save_analysis_report(connection)
        
        # 3. ä¿å­˜æ¨¡å‹ä¿¡æ¯
        print("\nğŸ¤– æ­¥éª¤3: ä¿å­˜æ¨¡å‹ä¿¡æ¯")
        save_model_info(connection)
        
        # 4. ä¿å­˜é¢„æµ‹ç»“æœ
        print("\nğŸ”® æ­¥éª¤4: ä¿å­˜é¢„æµ‹ç»“æœ")
        load_and_save_predictions(connection)
        
        # 5. ä¿å­˜å®¢æˆ·åˆ†ç¾¤ç»“æœ
        print("\nğŸ‘¥ æ­¥éª¤5: ä¿å­˜å®¢æˆ·åˆ†ç¾¤ç»“æœ")
        save_customer_segmentation(connection)
        
        print("\n" + "="*60)
        print("âœ… æ‰€æœ‰åˆ†æç»“æœå·²æˆåŠŸä¿å­˜åˆ°æ•°æ®åº“ï¼")
        
        # éªŒè¯ä¿å­˜ç»“æœ
        print("\nğŸ” éªŒè¯ä¿å­˜ç»“æœ:")
        with connection.cursor() as cursor:
            tables_to_check = [
                'analysis_reports',
                'model_info', 
                'prediction_results',
                'customer_segmentation',
                'feature_importance'
            ]
            
            for table in tables_to_check:
                cursor.execute(f"SELECT COUNT(*) FROM {table}")
                count = cursor.fetchone()[0]
                print(f"   ğŸ“Š {table}: {count} æ¡è®°å½•")
    
    except Exception as e:
        print(f"âŒ ä¿å­˜è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        return False
    
    finally:
        if 'connection' in locals():
            connection.close()
            print(f"\nğŸ”’ æ•°æ®åº“è¿æ¥å·²å…³é—­")
    
    return True

if __name__ == "__main__":
    print("ğŸ’¾ å¼€å§‹å°†åˆ†æç»“æœä¿å­˜åˆ°æ•°æ®åº“...")
    print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    success = main()
    
    if success:
        print("\nğŸ‰ åˆ†æç»“æœä¿å­˜å®Œæˆï¼ä½ çš„ç”µå•†æ•°æ®åˆ†æé¡¹ç›®ç°åœ¨å®Œå…¨ä¿å­˜åœ¨æ•°æ®åº“ä¸­äº†ï¼")
    else:
        print("\nğŸ˜ åˆ†æç»“æœä¿å­˜å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")